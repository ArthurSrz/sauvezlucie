---
title: Intelligence artificielle générale
type: concept
tags:
- IAG
- IA faible
- IA générale
- cognition artificielle
- intelligence humaine
- futurisme
- IA forte
- technologie
- intelligence artificielle
date_creation: '2025-04-08'
date_modification: '2025-04-08'
relatedTo:
- '[[Les enjeux de l''intelligence artificielle]]'
- '[[La philosophie de l''intelligence artificielle]]'
subClassOf: '[[La philosophie de l''intelligence artificielle]]'
---
## Généralité

L'[Intelligence Artificielle Générale](https://fr.wikipedia.org/wiki/Intelligence_artificielle_g%C3%A9n%C3%A9rale) (IAG), également connue sous le nom d'Intelligence Artificielle Forte, désigne un système d'intelligence artificielle hypothétique capable de comprendre, apprendre et appliquer des connaissances dans différents domaines avec une flexibilité et polyvalence approchant celle de l'intelligence humaine. Contrairement aux systèmes d'[IA](https://fr.wikipedia.org/wiki/Intelligence_artificielle) actuels qui sont spécialisés dans des tâches spécifiques (IA étroite ou faible), l'IAG pourrait potentiellement résoudre un large éventail de problèmes intellectuels comparables à ceux que les humains peuvent résoudre.

Le concept d'IAG s'inscrit dans le cadre plus large de la recherche en intelligence artificielle, qui vise à créer des machines capables de raisonnement autonome. Selon Wikipédia, l'IAG se distingue par plusieurs caractéristiques clés : la capacité d'abstraction, la compréhension du contexte, le transfert d'apprentissage entre différents domaines, et potentiellement une forme de conscience (bien que cette dernière caractéristique fasse l'objet de vifs débats scientifiques). Ces caractéristiques restent encore largement théoriques.

## Points clés

- **Capacités fondamentales** : L'IAG devrait posséder des capacités comme l'apprentissage autonome, le raisonnement abstrait, le transfert de connaissances, la conscience contextuelle et la créativité (voir [Apprentissage par transfert](https://fr.wikipedia.org/wiki/Apprentissage_par_transfert) et [Test de Turing](https://fr.wikipedia.org/wiki/Test_de_Turing))

- **Recherche actuelle** : Plusieurs approches sont explorées (neuronale, symbolique, hybride, évolutionnaire) mais aucune n'a encore abouti à une véritable IAG (voir [Transformers](https://fr.wikipedia.org/wiki/Transformer_(machine_learning)) et [Cyc](https://fr.wikipedia.org/wiki/Cyc))

- **Défis techniques** : Obstacles majeurs incluent le [problème difficile de la conscience](https://fr.wikipedia.org/wiki/Probl%C3%A8me_difficile_de_la_conscience), le développement du sens commun, et les mécanismes d'auto-amélioration sûrs

- **Implications éthiques** : Questions cruciales sur les risques existentiels, l'impact économique, la gouvernance et l'alignement des valeurs (voir [Future of Humanity Institute](https://fr.wikipedia.org/wiki/Future_of_Humanity_Institute))

- **Délais incertains** : Estimations variant considérablement parmi les experts, certains prédisant son avènement vers 2045 ([singularité technologique](https://fr.wikipedia.org/wiki/Singularit%C3%A9_technologique)), d'autres estimant qu'elle pourrait ne jamais être atteinte

## Détails

### Caractéristiques fondamentales de l'IAG

Une véritable Intelligence Artificielle Générale devrait posséder plusieurs capacités fondamentales :

1. **Apprentissage autonome** : capacité d'apprendre sans supervision humaine et d'améliorer ses propres algorithmes. Cette capacité d'auto-amélioration est au cœur du concept de "singularité technologique" où une IAG pourrait s'améliorer de manière exponentielle.

2. **Raisonnement abstrait** : aptitude à former des concepts abstraits et à raisonner sur des problèmes complexes. Cette capacité inclut la compréhension des métaphores, des analogies et des concepts philosophiques.

3. **Transfert de connaissances** : application des connaissances acquises dans un domaine à des problèmes dans d'autres domaines. Cette capacité, appelée "apprentissage par transfert", est considérée comme cruciale pour atteindre une intelligence de type humain.

4. **Conscience contextuelle** : compréhension du contexte et adaptation appropriée des réponses. Cela inclut la compréhension des nuances sociales et culturelles, ainsi que la capacité à passer des tests comme le test de Turing de manière convaincante dans tous les domaines.

5. **Créativité et innovation** : génération d'idées nouvelles et résolution de problèmes de façon originale. Une véritable IAG devrait pouvoir innover dans des domaines variés comme l'art, la science ou la philosophie.

### Approches de recherche actuelles

Plusieurs approches sont explorées pour développer l'IAG :

- **Approche neuronale** : développement de réseaux de neurones artificiels de plus en plus complexes et profonds, inspirés par le fonctionnement du cerveau biologique. Les architectures comme les transformers représentent des avancées significatives dans cette direction.

- **Approche symbolique** : formalisation logique de la connaissance et du raisonnement. Cette approche tente de coder explicitement les règles du sens commun et du raisonnement logique.

- **Approche hybride** : combinaison des méthodes neuronales et symboliques. Des projets tentent de combiner les forces des deux approches pour surmonter leurs limitations respectives.

- **Approche évolutionnaire** : utilisation d'[algorithmes génétiques](https://fr.wikipedia.org/wiki/Algorithme_g%C3%A9n%C3%A9tique) pour faire évoluer des systèmes intelligents. Cette méthode s'inspire de la sélection naturelle.

### Défis techniques

Le développement de l'IAG fait face à d'importants obstacles :

- La création d'architectures capables d'intégrer différents types d'apprentissage. Le "problème difficile de la conscience" souligne les défis à reproduire une véritable compréhension subjective.

- Le développement de systèmes dotés de sens commun et de compréhension contextuelle. Des projets tentent de relever ce défi en codant des millions de faits de sens commun.

- La conception de mécanismes d'auto-amélioration sûrs et contrôlables. Ce défi est au cœur des recherches sur l'[alignement de l'IA](https://fr.wikipedia.org/wiki/Alignement_de_l%27intelligence_artificielle).

- Les limitations matérielles en termes de puissance de calcul et d'efficacité énergétique. Le cerveau humain consomme environ 20 watts tout en surpassant les meilleurs supercalculateurs pour de nombreuses tâches cognitives.

### Implications et considérations éthiques

L'avènement potentiel de l'IAG soulève des questions fondamentales :

- **Risque existentiel** : une IAG pourrait-elle représenter une menace pour l'humanité si ses objectifs divergent des nôtres?

- **Impact économique** : comment gérer les bouleversements économiques liés à l'automatisation généralisée?

- **Gouvernance et contrôle** : quelles structures de gouvernance seraient nécessaires pour encadrer le développement de l'IAG?

- **Alignement des valeurs** : comment s'assurer que les systèmes d'IAG agissent conformément aux valeurs humaines? Le problème du contrôle, identifié dès 1960 par [Norbert Wiener](https://fr.wikipedia.org/wiki/Norbert_Wiener), reste largement non résolu.

La recherche sur l'alignement des valeurs et la sécurité de l'IA est devenue un domaine crucial, visant à garantir que tout système d'IAG futur reste bénéfique et contrôlable par l'humanité.

[1] https://fr.wikipedia.org/wiki/Intelligence_artificielle_g%C3%A9n%C3%A9rale  
[2] https://fr.wikipedia.org/wiki/Singularit%C3%A9_technologique  
[3] https://fr.wikipedia.org/wiki/Probl%C3%A8me_difficile_de_la_conscience  
[4] https://fr.wikipedia.org/wiki/Apprentissage_par_transfert  
[5] https://fr.wikipedia.org/wiki/Test_de_Turing  
[6] https://fr.wikipedia.org/wiki/Transformer_(machine_learning)  
[7] https://fr.wikipedia.org/wiki/Cyc  
[8] https://fr.wikipedia.org/wiki/Algorithme_g%C3%A9n%C3%A9tique  
[9] https://fr.wikipedia.org/wiki/Future_of_Humanity_Institute  
[10] https://fr.wikipedia.org/wiki/Alignement_de_l%27intelligence_artificielle  
[11] https://fr.wikipedia.org/wiki/Norbert_Wiener