---
title: Google Brain
type: organisation
tags:
- Google Brain
- Organisation
- Intelligence artificielle
- Google
- Recherche IA
- Tech
- Entreprise
date_creation: '2025-03-13'
date_modification: '2025-03-13'
isPartOf: '[[Google]]'
---
## Généralité

[Google Brain](https://fr.wikipedia.org/wiki/Google_Brain) est une équipe de recherche en intelligence artificielle fondée par Google. Initialement projet de recherche au sein de [Google X](https://fr.wikipedia.org/wiki/Google_X), elle est devenue une division à part entière spécialisée dans le machine learning et l'apprentissage profond. L'équipe a fusionné avec [DeepMind](https://fr.wikipedia.org/wiki/DeepMind) en 2023 pour former Google DeepMind.

## Points clés

- Fondée en 2011 par [Andrew Ng](https://fr.wikipedia.org/wiki/Andrew_Ng), Jeff Dean et Greg Corrado
- Développeur de technologies révolutionnaires comme [TensorFlow](https://fr.wikipedia.org/wiki/TensorFlow) et l'architecture Transformer
- Contributions majeures en NLP (BERT, LaMDA), vision par ordinateur et robotique
- Technologies intégrées dans de nombreux produits Google (Search, Translate, Assistant)
- Fusionné avec DeepMind en avril 2023 pour former Google DeepMind

## Détails

Google Brain a débuté comme projet de recherche au sein de Google X sous la direction d'Andrew Ng, Jeff Dean et Greg Corrado. L'équipe a marqué l'histoire en 2012 en construisant un système de réseau neuronal capable d'identifier des images de chats sur YouTube sans supervision, démontrant la puissance de l'[apprentissage profond](https://fr.wikipedia.org/wiki/Apprentissage_profond) à grande échelle.

Devenu équipe officielle en 2012, Google Brain a rapidement attiré des chercheurs de premier plan, publiant abondamment dans des conférences comme NeurIPS et ICML. La fusion avec DeepMind en 2023 a créé Google DeepMind sous la direction de [Demis Hassabis](https://fr.wikipedia.org/wiki/Demis_Hassabis).

Parmi ses contributions techniques majeures, on compte le framework open-source [TensorFlow](https://fr.wikipedia.org/wiki/TensorFlow) (2015), l'architecture Transformer (2017) et le modèle BERT qui ont révolutionné le traitement automatique du langage. L'équipe a aussi développé des systèmes de machine learning automatisé (AutoML) et réalisé des avancées significatives en apprentissage par renforcement appliqué à la robotique, ainsi que dans la génération de contenu via les GAN et autoencodeurs variationnels.

Ces technologies alimentent de nombreux produits Google comme l'algorithme RankBrain pour la recherche (2015), le système GNMT pour la traduction (2016) et les technologies de compréhension du langage pour l'Assistant Google.