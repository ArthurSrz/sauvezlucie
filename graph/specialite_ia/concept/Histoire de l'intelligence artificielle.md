---
title: Histoire de l'intelligence artificielle
type: concept
tags:
- intelligence artificielle
- histoire
- IA
- technologie
- informatique
- évolution technologique
- sciences
date_creation: '2025-03-24'
date_modification: '2025-03-24'
subClassOf: '[[Intelligence artificielle]]'
hasPart:
- '[[La conférence de Dartmouth]]'
- '[[Yann LeCun]]'
---
# Histoire de l'intelligence artificielle

## Généralité

L'histoire de l'intelligence artificielle est jalonnée d'innovations et de périodes de remise en question, depuis les premières modélisations théoriques des années 1940 jusqu'aux avancées récentes en deep learning.

## Points clés

- Les bases théoriques de l'IA remontent aux travaux de McCulloch et Pitts dans les années 1940
- La conférence de Dartmouth en 1956 marque la naissance officielle du domaine
- L'histoire de l'IA est marquée par des cycles d'enthousiasme et de "hivers" (périodes de désillusion)
- L'essor du machine learning et du deep learning a révolutionné le domaine depuis les années 1990-2000

## Détails

L'histoire de l'intelligence artificielle est jalonnée d'innovations et de périodes de remise en question. Dès les années 1940, les travaux de McCulloch et Pitts ont introduit l'idée d'un neurone artificiel en proposant un modèle logique inspiré du fonctionnement du cerveau. Cette approche pionnière a rapidement ouvert la voie à l'invention du perceptron dans les années 1950 par [Frank Rosenblatt](https://fr.wikipedia.org/wiki/Frank_Rosenblatt), marquant une étape majeure dans l'apprentissage supervisé et la reconnaissance de formes.

La conférence de Dartmouth en 1956, organisée par [John McCarthy](https://fr.wikipedia.org/wiki/John_McCarthy), [Marvin Minsky](https://fr.wikipedia.org/wiki/Marvin_Minsky), [Claude Shannon](https://fr.wikipedia.org/wiki/Claude_Shannon) et [Nathaniel Rochester](https://fr.wikipedia.org/wiki/Nathaniel_Rochester), est considérée comme l'acte fondateur de l'IA en tant que discipline. C'est d'ailleurs lors de cette conférence que McCarthy a proposé le terme "intelligence artificielle". Les années 1950-1960 ont ensuite connu un optimisme débordant, avec le développement des premiers programmes de résolution de problèmes comme le [Logic Theorist](https://fr.wikipedia.org/wiki/Logic_Theorist) et le [General Problem Solver](https://fr.wikipedia.org/wiki/General_Problem_Solver) par [Allen Newell](https://fr.wikipedia.org/wiki/Allen_Newell) et [Herbert Simon](https://fr.wikipedia.org/wiki/Herbert_Simon).

Les années 1970 ont marqué le premier "hiver de l'IA", suite aux critiques du rapport Lighthill (1973) qui remettait en question les progrès réalisés et les financements accordés. Cette période de désillusion a été suivie d'un regain d'intérêt dans les années 1980 avec l'émergence des systèmes experts et le projet japonais "Fifth Generation Computer". Cependant, un second hiver a suivi dans les années 1990, lorsque ces technologies n'ont pas répondu aux attentes commerciales.

Le tournant majeur s'est produit à partir des années 2000, avec la renaissance de l'apprentissage automatique grâce à l'augmentation de la puissance de calcul et la disponibilité de vastes ensembles de données. En 2012, la victoire éclatante du réseau de neurones profonds AlexNet lors de la compétition [ImageNet](https://fr.wikipedia.org/wiki/ImageNet) a déclenché la révolution du deep learning. Depuis, les avancées se sont accélérées avec des réalisations marquantes comme la victoire d'[AlphaGo](https://fr.wikipedia.org/wiki/AlphaGo) contre le champion du monde de Go en 2016, et plus récemment, l'émergence des grands modèles de langage comme GPT et des systèmes multimodaux capables d'intégrer texte, image et son.

Aujourd'hui, l'IA est entrée dans une phase d'application généralisée, transformant des secteurs entiers de l'économie et de la société, tout en soulevant d'importantes questions éthiques, juridiques et sociales qui façonneront son développement futur.