---
title: Test de Turing
type: concept
tags:
- intelligence artificielle
- test de Turing
- informatique
- philosophie
- Alan Turing
- cognition
- IA
- évaluation
date_creation: '2025-03-15'
date_modification: '2025-03-15'
createdBy: '[[Alan Turing]]'
relatedTo: '[[Intelligence artificielle]]'
isPartOf: '[[La philosophie de l''intelligence artificielle]]'
---
## Généralité

Le [test de Turing](https://fr.wikipedia.org/wiki/Test_de_Turing) est une méthode d'évaluation proposée par le mathématicien et informaticien britannique [Alan Turing](https://fr.wikipedia.org/wiki/Alan_Turing) en 1950 pour déterminer si une machine peut démontrer un comportement intelligent équivalent à celui d'un être humain. Dans son article fondateur "Computing Machinery and Intelligence" publié dans la revue Mind, Turing propose ce test comme une façon de répondre à la question "Les machines peuvent-elles penser ?", en remplaçant cette question philosophique par un test empirique plus concret.

## Points clés

- Le test implique un évaluateur humain qui engage des conversations textuelles avec un humain et une machine, sans savoir lequel est lequel (configuration appelée "jeu de l'imitation")
- Si l'évaluateur ne peut pas distinguer de manière fiable l'humain de la machine (avec un taux de réussite de 30% selon Turing), la machine est considérée comme ayant réussi le test
- Le test est devenu un concept fondamental dans les discussions sur l'[intelligence artificielle](https://fr.wikipedia.org/wiki/Intelligence_artificielle) et la philosophie de l'esprit
- Il a inspiré des variantes modernes comme le test de Lovelace 2.0 (créativité) et le test de Turing total (multimodal)
- Des compétitions comme le [prix Loebner](https://fr.wikipedia.org/wiki/Prix_Loebner) continuent d'utiliser des versions adaptées du test depuis 1991

## Détails

Dans sa forme classique, le test se déroule comme suit : un évaluateur humain engage des conversations textuelles avec deux participants invisibles - un humain et une machine. Les échanges se font typiquement par l'intermédiaire d'une interface texte pour garantir l'équité. Si après une série d'échanges (généralement limitée à 5 minutes selon les critères initiaux de Turing), l'évaluateur ne peut pas identifier de manière fiable qui est l'humain et qui est la machine, alors on considère que la machine a passé le test avec succès.

Alan Turing a proposé ce test en 1950 dans son article "Computing Machinery and Intelligence", à une époque où l'informatique en était à ses balbutiements. Turing envisageait déjà des versions plus sophistiquées de son test, incluant potentiellement des capacités d'apprentissage des machines. Il estimait qu'à l'horizon 2000, des machines pourraient réussir son test avec une probabilité de 30% après 5 minutes de conversation.

Le test de Turing a fait l'objet de nombreuses critiques, notamment l'argument de la "chambre chinoise" de [John Searle](https://fr.wikipedia.org/wiki/John_Searle) (1980) suggère qu'une machine pourrait simuler la compréhension sans réellement comprendre. D'autres critiques pointent que le test se concentre uniquement sur le comportement linguistique, ignorant d'autres aspects de l'intelligence, et qu'une machine pourrait réussir le test en imitant des comportements humains sans posséder une véritable intelligence.

Plusieurs variantes modernes du test ont été proposées, notamment le test de Turing total (Legg et Hutter, 2007) incluant des signaux visuels et auditifs, le test de Winograd qui se concentre sur la compréhension du langage naturel, le test de Lovelace 2.0 (2014) évaluant la créativité algorithmique, et le test d'embarquement minimal cherchant à isoler les signaux d'intelligence minimaux.

Avec l'avènement des grands modèles de langage comme [GPT](https://fr.wikipedia.org/wiki/Generative_Pre-trained_Transformer), [BERT](https://fr.wikipedia.org/wiki/BERT_(mod%C3%A8le_de_langage)) et [LaMDA](https://fr.wikipedia.org/wiki/LaMDA), la capacité des machines à produire du texte indiscernable de celui d'un humain s'est considérablement améliorée. Cependant, la question demeure : cette capacité reflète-t-elle une véritable intelligence ou simplement une simulation convaincante ? Le test reste pertinent comme jalon dans le développement de l'IA, même si la communauté scientifique reconnaît désormais qu'il ne constitue qu'une mesure partielle de l'intelligence artificielle.